import argparse
import os
import pickle
import subprocess
from pathlib import Path

import cv2
import numpy as np
from scipy import signal
from tqdm import tqdm


def parse_args():
    parser = argparse.ArgumentParser(description='Preprocess a single video file for lipreading')
    parser.add_argument('--video_file', type=str, required=True, help='Path to a single unprocessed video file')
    parser.add_argument('--track_file', type=str, required=True, help='Path to the corresponding track (*.pckl) file')
    parser.add_argument('--temp_dir', type=str, required=True, help='Directory for temporary files')
    parser.add_argument('--frame_rate', type=int, default=25, help='Frame rate of the video')
    parser.add_argument('--rank', type=int, default=0, help='Rank of the current process for logging consistency')
    parser.add_argument('--nshard', type=int, default=1, help='Total number of shards (kept for compatibility)')
    args = parser.parse_args()
    return args


args = parse_args()


# Append rank and shard to temp_dir to create unique directories for distributed processing
args.temp_dir = os.path.join(args.temp_dir, f"rank{args.rank}_of_{args.nshard}")

# Create the temporary directory if it doesn't exist
os.makedirs(args.temp_dir, exist_ok=True)


def _alias_numpy_core():
    import sys
    if 'numpy._core' not in sys.modules:
        try:
            import numpy.core as np_core
            sys.modules['numpy._core'] = np_core
            import numpy.core._multiarray_umath as umath
            sys.modules['numpy._core._multiarray_umath'] = umath
        except ImportError:
            pass


def _resolve_track_dict(track_data):
    """
    Accept dicts produced by dataset metadata as well as lists of entries generated by SyncNet (pywork).
    Returns a dict containing 'frame' and 'bbox' arrays or None.
    """
    candidates = []
    if isinstance(track_data, dict):
        candidates.append(track_data)
    elif isinstance(track_data, list):
        for entry in track_data:
            if isinstance(entry, dict):
                if 'track' in entry and isinstance(entry['track'], dict):
                    candidates.append(entry['track'])
                else:
                    candidates.append(entry)

    best = None
    best_len = -1
    for candidate in candidates:
        if not isinstance(candidate, dict):
            continue
        if 'bbox' in candidate and 'frame' in candidate:
            bbox_len = len(candidate['bbox'])
            if bbox_len > best_len:
                best = candidate
                best_len = bbox_len
    return best


def crop_video(track, args):
    track_path = Path(track)
    videofile = args.video_file
    temp_basename = track_path.stem
    temp_videofile = Path(args.temp_dir) / f"{temp_basename}.mp4"

    if not os.path.exists(videofile):
        print(f"[rank {args.rank}] skip - missing source video: {videofile}")
        return

    command = [
        'ffmpeg',
        '-i', videofile,
        '-r', str(args.frame_rate),
        '-y',
        str(temp_videofile)
    ]
    ret = subprocess.call(command)
    if ret != 0:
        print(f"[rank {args.rank}] skip - ffmpeg failed for {videofile}")
        return

    videofile = temp_videofile

    if not videofile.exists():
        print(f"[rank {args.rank}] skip - temp video not created: {videofile}")
        return

    cropfile = track_path.with_suffix('.mp4')
    if cropfile.exists():
        print(f"Cropped video file {cropfile} already exists")
        return

    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    vOut = cv2.VideoWriter(str(cropfile), fourcc, args.frame_rate, (224, 224))
    if not vOut.isOpened():
        print(f"[rank {args.rank}] skip - failed to open output video {cropfile}")
        return

    dets = {'x': [], 'y': [], 's': []}
    try:
        _alias_numpy_core()
        with open(track_path, 'rb') as f:
            track_data = pickle.load(f)
    except Exception as exc:
        print(f"[rank {args.rank}] skip - failed to load track {track_path}: {exc}")
        vOut.release()
        return

    track = _resolve_track_dict(track_data)
    if track is None:
        print(f"[rank {args.rank}] skip - invalid track format: {track_path}")
        vOut.release()
        return

    if len(track['bbox']) == 0 or len(track['frame']) == 0:
        print(f"[rank {args.rank}] skip - empty track data: {track_path}")
        vOut.release()
        return

    for det in track['bbox']:
        dets['s'].append(max((det[3] - det[1]), (det[2] - det[0])) / 2)
        dets['y'].append((det[1] + det[3]) / 2)
        dets['x'].append((det[0] + det[2]) / 2)

    try:
        dets['s'] = signal.medfilt(dets['s'], kernel_size=13)
        dets['x'] = signal.medfilt(dets['x'], kernel_size=13)
        dets['y'] = signal.medfilt(dets['y'], kernel_size=13)
    except ValueError as exc:
        print(f"[rank {args.rank}] skip - smoothing failed for {args.track_file}: {exc}")
        vOut.release()
        return

    frame_no_to_start = track['frame'][0]

    video_stream = cv2.VideoCapture(str(videofile))
    if not video_stream.isOpened():
        print(f"[rank {args.rank}] skip - cannot open video stream: {videofile}")
        vOut.release()
        return
    video_stream.set(cv2.CAP_PROP_POS_FRAMES, frame_no_to_start)

    frame_range = range(track['frame'][0], track['frame'][-1] + 1)
    for fidx, _ in enumerate(tqdm(frame_range,
                                  desc=f"frames r{args.rank}",
                                  unit="f",
                                  position=args.rank,
                                  leave=False)):
        if fidx >= len(dets['s']):
            print(f"[rank {args.rank}] warn - detection shorter than frame range for {videofile}")
            break

        cs = 0.4
        bs = dets['s'][fidx]
        bsi = int(bs * (1 + 2 * cs))

        ok, image = video_stream.read()
        if not ok or image is None:
            print(f"[rank {args.rank}] warn - failed to read frame at idx {fidx}")
            break

        frame = np.pad(image, ((bsi, bsi), (bsi, bsi), (0, 0)), 'constant', constant_values=(110, 110))

        my = dets['y'][fidx] + bsi
        mx = dets['x'][fidx] + bsi

        face = frame[int(my - bs):int(my + bs * (1 + 2 * cs)), int(mx - bs * (1 + cs)):int(mx + bs * (1 + cs))]

        if face is not None and face.size != 0:
            vOut.write(cv2.resize(face, (224, 224)))
        else:
            print(f"[rank {args.rank}] warn - empty face at {videofile}")
            continue

    video_stream.release()
    vOut.release()
    # ========== CROP AUDIO FILE ==========

    # command = ("ffmpeg -y -i %s -ss %.3f -to %.3f %s" % (os.path.join(args.temp_dir, 'audio.wav'),audiostart,audioend,audiotmp)) 
    # output = subprocess.call(command, shell=True, stdout=None)

    # ========== COMBINE AUDIO AND VIDEO FILES ==========
    # copy(audiotmp, cropfile.replace('.mp4', '.wav'))
    
    print('Written %s' %cropfile)


if __name__ == "__main__":
    if not os.path.exists(args.track_file):
        raise FileNotFoundError(f"Track file not found: {args.track_file}")

    crop_video(args.track_file, args)
