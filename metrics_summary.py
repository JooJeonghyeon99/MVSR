import argparse
import json
from collections import defaultdict
from pathlib import Path


def main() -> None:
    parser = argparse.ArgumentParser(description="Summarize inference metrics")
    parser.add_argument(
        "--metrics_path",
        required=True,
        help="Path to the JSONL metrics file generated by inference_single.py",
    )
    args = parser.parse_args()

    metrics_file = Path(args.metrics_path)
    if not metrics_file.exists():
        raise FileNotFoundError(f"Metrics file not found: {metrics_file}")

    total_errors = 0
    total_words = 0
    total_samples = 0
    hits = 0

    lang_stats = defaultdict(lambda: {
        "errors": 0,
        "words": 0,
        "samples": 0,
        "hits": 0,
    })

    with metrics_file.open("r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            data = json.loads(line)

            total_samples += 1
            target_lang = data.get("target_lang", "unknown") or "unknown"
            pred_lang = data.get("pred_lang", "unknown") or "unknown"

            lang_entry = lang_stats[target_lang]
            lang_entry["samples"] += 1

            if pred_lang == target_lang and target_lang != "unknown":
                hits += 1
                lang_entry["hits"] += 1

            if data.get("has_reference"):
                errors = data.get("errors")
                words = data.get("words")
                if errors is None or words is None:
                    continue
                errors = int(errors)
                words = int(words)
                total_errors += errors
                total_words += words
                lang_entry["errors"] += errors
                lang_entry["words"] += words

    if total_words:
        overall_wer = total_errors / total_words
        print(f"Overall WER: {overall_wer * 100:.2f}% (errors={total_errors}, words={total_words})")
    else:
        print("Overall WER: N/A (no references)")

    if total_samples:
        acc = hits / total_samples
        print(f"Language accuracy: {hits}/{total_samples} ({acc * 100:.2f}%)")
    else:
        print("Language accuracy: N/A (no samples)")

    if lang_stats:
        print("\nLanguage breakdown:")
        for lang in sorted(lang_stats.keys()):
            stats = lang_stats[lang]
            words = stats["words"]
            errors = stats["errors"]
            samples = stats["samples"]
            hits_lang = stats["hits"]

            if words:
                lang_wer = errors / words
                wer_str = f"WER {lang_wer * 100:.2f}% (errors={errors}, words={words})"
            else:
                wer_str = "WER N/A"

            if samples:
                acc_lang = hits_lang / samples * 100
                acc_str = f"accuracy {hits_lang}/{samples} ({acc_lang:.2f}%)"
            else:
                acc_str = "accuracy N/A"

            print(f"  {lang}: {wer_str}, {acc_str}")


if __name__ == "__main__":
    main()
